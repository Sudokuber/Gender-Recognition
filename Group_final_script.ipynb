{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import cv2    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Remove some unwanted warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [PlotLearning()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download content from Kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
    "! kaggle datasets download maciejgronczynski/biggest-genderface-recognition-dataset\n",
    "! kaggle datasets download rashikrahmanpritom/gender-recognition-dataset\n",
    "\n",
    "# unzip packs\n",
    "! unzip biggest-genderface-recognition-dataset.zip\n",
    "! unzip gender-recognition-dataset.zip\n",
    "\n",
    "# manage paths\n",
    "!mv faces test_data\n",
    "!mv Train/Train train_data\n",
    "!mv Test/Test val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = ['Male','Female']\n",
    "path = '/content/train_data/'\n",
    "\n",
    "# Creating train set\n",
    "x_train, y_train = [], []\n",
    "for gender in subdir:\n",
    "    for img_name in os.listdir(path+gender): \n",
    "        img = cv2.imread(path+gender+'/'+img_name) \n",
    "        x_train.append(img)\n",
    "        if gender=='Male':\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = ['Male','Female']\n",
    "path = '/content/val_data/'\n",
    "\n",
    "x_val, y_val = [], []\n",
    "for gender in subdir:\n",
    "    for img_name in os.listdir(path+gender):\n",
    "        img = cv2.imread(path+gender+'/'+img_name)\n",
    "\n",
    "        x_val.append(img)\n",
    "        if gender=='Male':\n",
    "            y_val.append(1)\n",
    "        else:\n",
    "            y_val.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test  set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = ['man','woman']\n",
    "path = '/content/test_data/'\n",
    "\n",
    "x_test, y_test = [], []\n",
    "for gender in subdir:\n",
    "    for img_name in os.listdir(path+gender):\n",
    "        img = cv2.imread(path+gender+'/'+img_name)\n",
    "        img = cv2.resize(img, (100, 100)) \n",
    "        x_test.append(img)\n",
    "        \n",
    "        if gender=='man':\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).astype('float32')/255\n",
    "x_val = np.array(x_val).astype('float32')/255\n",
    "x_test = np.array(x_test).astype('float32')/255\n",
    "\n",
    "y_train = np.array(y_train).astype(int)\n",
    "y_val = np.array(y_val).astype(int)\n",
    "y_test = np.array(y_test).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Input((100, 100, 3)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hist = model.fit(x_train, y_train,\n",
    "                      validation_data=(x_val, y_val),\n",
    "                      epochs=25, \n",
    "                      batch_size=32, \n",
    "                      verbose=1,\n",
    "                      callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_3 = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, \n",
    "                                 height_shift_range=0.1, \n",
    "                                 rotation_range=10, \n",
    "                                 zoom_range=0.1,\n",
    "                                 horizontal_flip=True)\n",
    "x_train_1 = generator_3.flow(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(layers.Input((100, 100, 3)))\n",
    "\n",
    "model_3.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model_3.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model_3.add(layers.MaxPooling2D((2)))\n",
    "\n",
    "model_3.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model_3.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model_3.add(layers.MaxPooling2D((2)))\n",
    "\n",
    "model_3.add(layers.Flatten())\n",
    "model_3.add(layers.Dense(64, activation='relu'))\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(64, activation='relu'))\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6 = model_3.fit(x_train_1,\n",
    "                        epochs=50,\n",
    "                        batch_size=64,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze every layer\n",
    "vggmodel.trainable = False\n",
    "\n",
    "# chain up the vgg16 architecture and the fully connected layer of the baseline model\n",
    "last = vggmodel.layers[-1].output\n",
    "x = layers.Flatten()(last)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_vgg = Model(vggmodel.input, output)\n",
    "model_vgg.summary()\n",
    "\n",
    "model_vgg.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 32\n",
    "hist_vgg = model_vgg.fit(x_train_1,\n",
    "                         batch_size=32,\n",
    "                         steps_per_epoch=len(x_train)//Batch_size, \n",
    "                         epochs=25, \n",
    "                         validation_data=(x_val, y_val), \n",
    "                         validation_steps=len(x_val)//Batch_size, \n",
    "                         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histV = hist_vgg.history\n",
    "round(sum(histV['val_accuracy'])/len(histV['val_accuracy']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "y_val_base_pred = model.predict(x_val)\n",
    "y_val_base_pred_label = (y_val_base_pred > 0.5).astype(np.int)\n",
    "# y_val_base_pred_label\n",
    "\n",
    "# tuned model\n",
    "y_val_tune_pred = model_3.predict(x_val)\n",
    "y_val_tune_pred_label = (y_val_base_pred > 0.5).astype(np.int)\n",
    "# y_val_tune_pred_label\n",
    "\n",
    "# tf model\n",
    "y_val_tf_pred = model_vgg.predict(x_val)\n",
    "y_val_tf_pred_label = (y_val_tf_pred > 0.5).astype(np.int)\n",
    "# y_val_tf_pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "y_test_base_pred = model.predict(x_test)\n",
    "y_test_base_pred_label = (y_test_base_pred > 0.5).astype(np.int)\n",
    "# y_test_base_pred_label\n",
    "\n",
    "# tuned model\n",
    "y_test_tune_pred = model_3.predict(x_test)\n",
    "y_test_tune_pred_label = (y_test_tune_pred > 0.5).astype(np.int)\n",
    "# y_test_tune_pred_label\n",
    "\n",
    "# tf model\n",
    "y_test_tf_pred = model_vgg.predict(x_test)\n",
    "y_test_tf_pred_label = (y_test_tf_pred > 0.5).astype(np.int)\n",
    "# y_test_tf_pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss & Accuracy (Train + Validation Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
    "index = ['Base Model', 'Fine Tuned Model', 'Transfer Learning Model']\n",
    "histB = base_hist.history\n",
    "histT = history_6.history\n",
    "histV = hist_vgg.history\n",
    "\n",
    "hist = np.array([histB, histT, histV])\n",
    "data = []\n",
    "for i in range(len(index)):\n",
    "    temp = []\n",
    "    # get the average acc & loss over all epochs\n",
    "    for h in range(len(header)):\n",
    "        temp.append(round(sum(hist[i][header[h]]) / len(hist[i][header[h]]), 7))\n",
    "    data.append(temp)\n",
    "\n",
    "loss_acc = pd.DataFrame(data, columns=header, index=index)\n",
    "print(loss_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC & AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = [y_val_base_pred_label, y_val_tune_pred_label, y_val_tf_pred_label]\n",
    "test_preds = [y_test_base_pred_label, y_test_tune_pred_label, y_test_tf_pred_label]\n",
    "\n",
    "# plot ROC\n",
    "def plot_roc(fpr, tpr, i, dataset, auc_score):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.title('Model {} ROC Curve ({} set)'.format(i, dataset))\n",
    "    plt.xlabel('False Positive Rate (Positive label: 1)') \n",
    "    plt.ylabel('True Positive Rate (Positive label: 1)') \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "def roc_auc(y_true, y_pred, dataset):\n",
    "    for i in range(len(y_pred)):\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred[i])\n",
    "        auc_score = roc_auc_score(y_true, y_pred[i])\n",
    "        plot_roc(fpr, tpr, i, dataset, auc_score)\n",
    "        #print('Model {} AUC score on {} set: {}'.format(i, dataset, round(auc_score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(y_val, val_preds, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(y_test, test_preds, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix + Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_classification(y_true, y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        print('Model {} confusion matrix'.format(i))\n",
    "        print(tf.math.confusion_matrix(y_true, y_pred[i]))\n",
    "        print('')\n",
    "        print('Model {} classification_report'.format(i))\n",
    "        print(classification_report(y_true, y_pred[i]))\n",
    "        print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "confusion_classification(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "confusion_classification(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline validation confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_base_val = confusion_matrix(y_val, y_val_base_pred_label.ravel())\n",
    "sns.heatmap(cm_base_val, annot = True, fmt = '.20g')\n",
    "ax.set_title('Baseline Model Confusion Matrix on Validation Data')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline test confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_base_test = confusion_matrix(y_test, y_test_base_pred_label.ravel())\n",
    "sns.heatmap(cm_base_test, annot = True, fmt = '.20g')\n",
    "ax.set_title('Baseline Model Confusion Matrix on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning validation confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_best_val = confusion_matrix(y_val, y_val_best_pred_label.ravel())\n",
    "sns.heatmap(cm_best_val, annot = True, fmt = '.20g')\n",
    "ax.set_title(' Fine-tuned Model Confusion Matrix on Validation Data')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning test confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_best_test = confusion_matrix(y_test, y_test_best_pred_label.ravel())\n",
    "sns.heatmap(cm_best_test, annot = True, fmt = '.20g')\n",
    "ax.set_title('Fine-tuned Model Confusion Matrix on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning validation confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_vgg_val = confusion_matrix(y_val, y_val_vgg_pred_label.ravel())\n",
    "sns.heatmap(cm_vgg_val, annot = True, fmt = '.20g')\n",
    "ax.set_title('Vgg Model Confusion Matrix on Validation Data')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning test confusion matrix\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "ax = plt.axes()\n",
    "cm_vgg_test = confusion_matrix(y_test, y_test_vgg_pred_label.ravel())\n",
    "sns.heatmap(cm_base_test, annot = True, fmt = '.20g')\n",
    "ax.set_title('Vgg Model Confusion Matrix on Test Data')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
